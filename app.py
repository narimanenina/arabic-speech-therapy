import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import librosa
import soundfile as sf
from streamlit_mic_recorder import mic_recorder
from datetime import datetime

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª ---
st.set_page_config(page_title="Ù…Ù‚ÙŠÙ… Ù†Ø·Ù‚ Ø§Ù„Ø£Ø·ÙØ§Ù„", layout="centered")

st.markdown("""
    <style>
    .report-card {
        background-color: white; padding: 20px; border-radius: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1); border-right: 5px solid #2196F3;
        margin-bottom: 20px; color: #333;
    }
    h1 { color: #1E3A8A; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

@st.cache_data
def load_data():
    if os.path.exists('arabic_phonetics.csv'):
        return pd.read_csv('arabic_phonetics.csv')
    return None

df = load_data()

# --- 2. ÙˆØ¸ÙŠÙØ© Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø¶Ù‰ ---
def save_to_database(name, age, target, spoken, accuracy, report_text):
    db_file = 'patient_records.csv'
    new_entry = {
        'Ø§Ù„ØªØ§Ø±ÙŠØ®': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„': name,
        'Ø§Ù„Ø¹Ù…Ø±': age,
        'Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù': target,
        'Ù†Ø·Ù‚ Ø§Ù„Ø·ÙÙ„': spoken,
        'Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­': f"{accuracy}%",
        'Ø§Ù„ØªØ´Ø®ÙŠØµ': " | ".join(report_text)
    }
    
    df_new = pd.DataFrame([new_entry])
    
    if not os.path.isfile(db_file):
        df_new.to_csv(db_file, index=False, encoding='utf-8-sig')
    else:
        df_new.to_csv(db_file, mode='a', index=False, header=False, encoding='utf-8-sig')

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ´Ø®ÙŠØµ (Ù†ÙØ³ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø³Ø§Ø¨Ù‚) ---
def run_diagnosis(target, spoken):
    if df is None: return [], "", "", 0
    matcher = difflib.SequenceMatcher(None, target, spoken)
    report, t_ipa, s_ipa = [], [], []
    accuracy = round(matcher.ratio() * 100, 1)

    for char in target:
        row = df[df['letter'] == char] if char != " " else None
        t_ipa.append(row.iloc[0]['ipa'] if row is not None and not row.empty else char)

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        t_p, s_p = target[i1:i2], spoken[j1:j2]
        if tag == 'replace':
            for tc, sc in zip(t_p, s_p):
                t_row, s_row = df[df['letter'] == tc], df[df['letter'] == sc]
                if not t_row.empty and not s_row.empty:
                    report.append(f"ğŸ”„ Ø¥Ø¨Ø¯Ø§Ù„: ({sc}) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ({tc}) | Ø§Ù„Ù…Ø®Ø±Ø¬: {t_row.iloc[0]['place']} â† {s_row.iloc[0]['place']}")
                    s_ipa.append(s_row.iloc[0]['ipa'])
        elif tag == 'delete':
            for char in t_p: report.append(f"âŒ Ø­Ø°Ù: Ø­Ø±Ù ({char})")
        elif tag == 'insert':
            for char in s_p:
                report.append(f"â• Ø¥Ø¶Ø§ÙØ©: Ø­Ø±Ù ({char})")
                s_row = df[df['letter'] == char]
                if not s_row.empty: s_ipa.append(s_row.iloc[0]['ipa'])
        elif tag == 'equal':
            for char in s_p:
                s_row = df[df['letter'] == char]
                s_ipa.append(s_row.iloc[0]['ipa'] if not s_row.empty else char)
                    
    return report, "".join(t_ipa), "".join(s_ipa), accuracy

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title(" ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒÙ„Ø§Ù… Ù„Ø¯Ù‰ Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø°ÙˆÙŠ Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ÙÙˆÙ†ÙˆÙ„ÙˆØ¬ÙŠ")

if df is not None:
    with st.expander("ğŸ‘¤ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·ÙÙ„", expanded=True):
        c1, c2 = st.columns(2)
        child_name = c1.text_input("Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„:", placeholder="Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„")
        child_age = c2.number_input("Ø§Ù„Ø¹Ù…Ø±:", 2, 15, 5)

    target_text = st.text_input("ğŸ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:", "Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨")
    record = mic_recorder(start_prompt="Ø§Ø¨Ø¯Ø£ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª ğŸ¤", stop_prompt="ØªÙˆÙ‚Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„ â¹ï¸", key='recorder')
    
    spoken_text = ""
    if record:
        st.audio(record['bytes'])
        try:
            y, sr_rate = librosa.load(io.BytesIO(record['bytes']), sr=16000)
            buf = io.BytesIO(); sf.write(buf, y, sr_rate, format='WAV', subtype='PCM_16'); buf.seek(0)
            r = sr.Recognizer()
            with sr.AudioFile(buf) as source: spoken_text = r.recognize_google(r.record(source), language="ar-SA")
            st.success(f"Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: **{spoken_text}**")
        except: st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª.")

    if spoken_text and target_text:
        res, tipa, sipa, acc = run_diagnosis(target_text, spoken_text)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø¨Ø·Ø§Ù‚Ø©
        st.markdown(f"<div class='report-card'><h3>ğŸ“Š ØªÙ‚Ø±ÙŠØ±: {child_name}</h3><p>Ø¯Ù‚Ø© Ø§Ù„Ù†Ø·Ù‚: {acc}%</p></div>", unsafe_allow_html=True)
        st.write(f"**IPA Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:** `/{tipa}/` | **Ø§Ù„Ù…Ù†Ø·ÙˆÙ‚:** `/{sipa}/`")
        
        # --- Ø²Ø± Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ---
        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©"):
            if not child_name:
                st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„ Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸.")
            else:
                save_to_database(child_name, child_age, target_text, spoken_text, acc, res)
                st.success(f"ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± {child_name} Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ù„Ù patient_records.csv")

        st.divider()
        if res:
            st.subheader("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:")
            for line in res: st.info(line)

    # --- Ø®ÙŠØ§Ø± Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­ÙÙˆØ¸ ---
    if st.sidebar.button("ğŸ“‚ Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©"):
        if os.path.exists('patient_records.csv'):
            st.sidebar.write(pd.read_csv('patient_records.csv'))
        else:
            st.sidebar.write("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø¹Ø¯.")

else:
    st.error("Ù…Ù„Ù 'arabic_phonetics.csv' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")