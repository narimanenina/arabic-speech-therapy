import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import re
from pydub import AudioSegment
from streamlit_mic_recorder import mic_recorder
from datetime import datetime

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØµÙ…ÙŠÙ… ---
st.set_page_config(page_title="Ù…Ù‚ÙŠÙ… Ù†Ø·Ù‚ Ø§Ù„Ø£Ø·ÙØ§Ù„", layout="centered")

# Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
def clean_arabic(text):
    noise = re.compile(r'[\u064B-\u0652]') # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    return re.sub(noise, '', text).strip()

@st.cache_data
def load_data():
    if os.path.exists('arabic_phonetics.csv'):
        return pd.read_csv('arabic_phonetics.csv')
    return None

df = load_data()

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ÙÙˆÙ†ÙˆÙ„ÙˆØ¬ÙŠ ---
def run_diagnosis(target, spoken):
    if df is None: return [], "", "", 0
    target, spoken = clean_arabic(target), clean_arabic(spoken)
    matcher = difflib.SequenceMatcher(None, target, spoken)
    report, t_ipa, s_ipa = [], [], []
    accuracy = round(matcher.ratio() * 100, 1)

    for char in target:
        row = df[df['letter'] == char] if char != " " else None
        t_ipa.append(row.iloc[0]['ipa'] if row is not None and not row.empty else char)

    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        t_p, s_p = target[i1:i2], spoken[j1:j2]
        if tag == 'replace':
            for tc, sc in zip(t_p, s_p):
                t_row, s_row = df[df['letter'] == tc], df[df['letter'] == sc]
                if not t_row.empty and not s_row.empty:
                    tr, sr = t_row.iloc[0], s_row.iloc[0]
                    report.append(f"ğŸ”„ **Ø¥Ø¨Ø¯Ø§Ù„**: ({sc}) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ({tc})")
                    report.append(f"   - Ù…Ø®Ø±Ø¬ {tr['name']}: {tr['place']} ({tr['manner']})")
                    report.append(f"   - Ù…Ø®Ø±Ø¬ {sr['name']}: {sr['place']} ({sr['manner']})")
                    s_ipa.append(sr['ipa'])
        elif tag == 'delete':
            for char in t_p: report.append(f"âŒ **Ø­Ø°Ù**: Ø­Ø±Ù ({char})")
        elif tag == 'insert':
            for char in s_p:
                report.append(f"â• **Ø¥Ø¶Ø§ÙØ©**: Ø­Ø±Ù ({char})")
                s_row = df[df['letter'] == char]
                if not s_row.empty: s_ipa.append(s_row.iloc[0]['ipa'])
        elif tag == 'equal':
            for char in s_p:
                s_row = df[df['letter'] == char]
                s_ipa.append(s_row.iloc[0]['ipa'] if not s_row.empty else char)
                    
    return report, "".join(t_ipa), "".join(s_ipa), accuracy

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ”¬ Ù…Ø­Ù„Ù„ Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ÙÙˆÙ†ÙˆÙ„ÙˆØ¬ÙŠ")

if df is not None:
    target_text = st.text_input("ğŸ¯ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ù†Ø¹Ù…")
    
    st.write("---")
    st.subheader("ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ù†Ø·Ù‚ Ø§Ù„Ø·ÙÙ„")
    record = mic_recorder(start_prompt="Ø³Ø¬Ù„ Ø§Ù„Ø¢Ù†", stop_prompt="ØªÙˆÙ‚Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„", key='recorder')
    
    # Ù…ØªØºÙŠØ± Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªØ´Ø®ÙŠØµÙ‡
    final_spoken = ""

    if record:
        st.audio(record['bytes'])
        try:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                audio_segment = AudioSegment.from_file(io.BytesIO(record['bytes']))
                wav_io = io.BytesIO()
                audio_segment.export(wav_io, format="wav", parameters=["-acodec", "pcm_s16le", "-ar", "16000"])
                wav_io.seek(0)
                r = sr.Recognizer()
                with sr.AudioFile(wav_io) as source:
                    audio_content = r.record(source)
                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ù…Ù† Ø¬ÙˆØ¬Ù„
                    ai_text = r.recognize_google(audio_content, language="ar-SA")
                    
            # Ø§Ù„Ø­Ù„ Ù‡Ù†Ø§: Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨ØªØ£ÙƒÙŠØ¯ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ø³Ù…Ø¹Ù‡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
            st.warning("âš ï¸ Ø¥Ø°Ø§ Ù‚Ø§Ù… Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨ØªØµØ­ÙŠØ­ Ø§Ù„ÙƒÙ„Ù…Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø£Ø¯Ù†Ø§Ù‡ Ù„ØªØ·Ø§Ø¨Ù‚ Ù…Ø§ Ù‚Ø§Ù„Ù‡ Ø§Ù„Ø·ÙÙ„ ÙØ¹Ù„ÙŠØ§Ù‹:")
            final_spoken = st.text_input("Ù…Ø§ Ù‚Ø§Ù„Ù‡ Ø§Ù„Ø·ÙÙ„ ÙØ¹Ù„ÙŠØ§Ù‹ (ØªØ¹Ø¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±):", ai_text)
            
        except Exception:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹.")
            final_spoken = st.text_input("Ø§ÙƒØªØ¨ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªÙŠ Ù†Ø·Ù‚Ù‡Ø§ Ø§Ù„Ø·ÙÙ„ Ù‡Ù†Ø§:")

    if final_spoken:
        res, tipa, sipa, acc = run_diagnosis(target_text, final_spoken)
        
        st.divider()
        st.metric("Ù†Ø³Ø¨Ø© ØµØ­Ø© Ø§Ù„Ù†Ø·Ù‚", f"{acc}%")
        
        c1, c2 = st.columns(2)
        c1.info(f"**IPA Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:** `/{tipa}/`")
        c2.success(f"**IPA Ø§Ù„Ù…Ø³Ù…ÙˆØ¹:** `/{sipa}/`")
        
        if res:
            st.subheader("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for line in res:
                st.write(line)
        else:
            st.balloons()
            st.success("Ø£Ø­Ø³Ù†Øª! Ø§Ù„Ù†Ø·Ù‚ Ø³Ù„ÙŠÙ….")

else:
    st.error("ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù arabic_phonetics.csv")


