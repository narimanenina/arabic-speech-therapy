import streamlit as st
import pandas as pd
import speech_recognition as sr
import io
import difflib
import os
import re
from pydub import AudioSegment
from streamlit_mic_recorder import mic_recorder
from datetime import datetime

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØµÙ…ÙŠÙ… ---
st.set_page_config(page_title="Ù…Ù‚ÙŠÙ… Ù†Ø·Ù‚ Ø§Ù„Ø£Ø·ÙØ§Ù„", layout="centered")

# Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
def clean_arabic(text):
Â  Â  noise = re.compile(r'[\u064B-\u0652]') # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
Â  Â  return re.sub(noise, '', text).strip()

@st.cache_data
def load_data():
Â  Â  if os.path.exists('arabic_phonetics.csv'):
Â  Â  Â  Â  return pd.read_csv('arabic_phonetics.csv')
Â  Â  return None

df = load_data()

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ÙÙˆÙ†ÙˆÙ„ÙˆØ¬ÙŠ ---
def run_diagnosis(target, spoken):
Â  Â  if df is None: return [], "", "", 0
Â  Â  target, spoken = clean_arabic(target), clean_arabic(spoken)
Â  Â  matcher = difflib.SequenceMatcher(None, target, spoken)
Â  Â  report, t_ipa, s_ipa = [], [], []
Â  Â  accuracy = round(matcher.ratio() * 100, 1)

Â  Â  for char in target:
Â  Â  Â  Â  row = df[df['letter'] == char] if char != " " else None
Â  Â  Â  Â  t_ipa.append(row.iloc[0]['ipa'] if row is not None and not row.empty else char)

Â  Â  for tag, i1, i2, j1, j2 in matcher.get_opcodes():
Â  Â  Â  Â  t_p, s_p = target[i1:i2], spoken[j1:j2]
Â  Â  Â  Â  if tag == 'replace':
Â  Â  Â  Â  Â  Â  for tc, sc in zip(t_p, s_p):
Â  Â  Â  Â  Â  Â  Â  Â  t_row, s_row = df[df['letter'] == tc], df[df['letter'] == sc]
Â  Â  Â  Â  Â  Â  Â  Â  if not t_row.empty and not s_row.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tr, sr = t_row.iloc[0], s_row.iloc[0]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  report.append(f"ğŸ”„ **Ø¥Ø¨Ø¯Ø§Ù„**: ({sc}) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ({tc})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  report.append(f"Â  Â - Ù…Ø®Ø±Ø¬ {tr['name']}: {tr['place']} ({tr['manner']})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  report.append(f"Â  Â - Ù…Ø®Ø±Ø¬ {sr['name']}: {sr['place']} ({sr['manner']})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  s_ipa.append(sr['ipa'])
Â  Â  Â  Â  elif tag == 'delete':
Â  Â  Â  Â  Â  Â  for char in t_p: report.append(f"âŒ **Ø­Ø°Ù**: Ø­Ø±Ù ({char})")
Â  Â  Â  Â  elif tag == 'insert':
Â  Â  Â  Â  Â  Â  for char in s_p:
Â  Â  Â  Â  Â  Â  Â  Â  report.append(f"â• **Ø¥Ø¶Ø§ÙØ©**: Ø­Ø±Ù ({char})")
Â  Â  Â  Â  Â  Â  Â  Â  s_row = df[df['letter'] == char]
Â  Â  Â  Â  Â  Â  Â  Â  if not s_row.empty: s_ipa.append(s_row.iloc[0]['ipa'])
Â  Â  Â  Â  elif tag == 'equal':
Â  Â  Â  Â  Â  Â  for char in s_p:
Â  Â  Â  Â  Â  Â  Â  Â  s_row = df[df['letter'] == char]
Â  Â  Â  Â  Â  Â  Â  Â  s_ipa.append(s_row.iloc[0]['ipa'] if not s_row.empty else char)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  return report, "".join(t_ipa), "".join(s_ipa), accuracy

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.title("ğŸ”¬ Ù…Ø­Ù„Ù„ Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ÙÙˆÙ†ÙˆÙ„ÙˆØ¬ÙŠ")

if df is not None:
Â  Â  target_text = st.text_input("ğŸ¯ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", "Ù†Ø¹Ù…")
Â  Â Â 
Â  Â  st.write("---")
Â  Â  st.subheader("ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ù†Ø·Ù‚ Ø§Ù„Ø·ÙÙ„")
Â  Â  record = mic_recorder(start_prompt="Ø³Ø¬Ù„ Ø§Ù„Ø¢Ù†", stop_prompt="ØªÙˆÙ‚Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„", key='recorder')
Â  Â Â 
Â  Â  # Ù…ØªØºÙŠØ± Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªØ´Ø®ÙŠØµÙ‡
Â  Â  final_spoken = ""

Â  Â  if record:
Â  Â  Â  Â  st.audio(record['bytes'])
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
Â  Â  Â  Â  Â  Â  Â  Â  audio_segment = AudioSegment.from_file(io.BytesIO(record['bytes']))
Â  Â  Â  Â  Â  Â  Â  Â  wav_io = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  audio_segment.export(wav_io, format="wav", parameters=["-acodec", "pcm_s16le", "-ar", "16000"])
Â  Â  Â  Â  Â  Â  Â  Â  wav_io.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  r = sr.Recognizer()
Â  Â  Â  Â  Â  Â  Â  Â  with sr.AudioFile(wav_io) as source:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audio_content = r.record(source)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ù…Ù† Ø¬ÙˆØ¬Ù„
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ai_text = r.recognize_google(audio_content, language="ar-SA")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Ø§Ù„Ø­Ù„ Ù‡Ù†Ø§: Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨ØªØ£ÙƒÙŠØ¯ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ø³Ù…Ø¹Ù‡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ Ø¥Ø°Ø§ Ù‚Ø§Ù… Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨ØªØµØ­ÙŠØ­ Ø§Ù„ÙƒÙ„Ù…Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø£Ø¯Ù†Ø§Ù‡ Ù„ØªØ·Ø§Ø¨Ù‚ Ù…Ø§ Ù‚Ø§Ù„Ù‡ Ø§Ù„Ø·ÙÙ„ ÙØ¹Ù„ÙŠØ§Ù‹:")
Â  Â  Â  Â  Â  Â  final_spoken = st.text_input("Ù…Ø§ Ù‚Ø§Ù„Ù‡ Ø§Ù„Ø·ÙÙ„ ÙØ¹Ù„ÙŠØ§Ù‹ (ØªØ¹Ø¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±):", ai_text)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹.")
Â  Â  Â  Â  Â  Â  final_spoken = st.text_input("Ø§ÙƒØªØ¨ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªÙŠ Ù†Ø·Ù‚Ù‡Ø§ Ø§Ù„Ø·ÙÙ„ Ù‡Ù†Ø§:")

Â  Â  if final_spoken:
Â  Â  Â  Â  res, tipa, sipa, acc = run_diagnosis(target_text, final_spoken)
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.divider()
Â  Â  Â  Â  st.metric("Ù†Ø³Ø¨Ø© ØµØ­Ø© Ø§Ù„Ù†Ø·Ù‚", f"{acc}%")
Â  Â  Â  Â Â 
Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  c1.info(f"**IPA Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:** `/{tipa}/`")
Â  Â  Â  Â  c2.success(f"**IPA Ø§Ù„Ù…Ø³Ù…ÙˆØ¹:** `/{sipa}/`")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if res:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
Â  Â  Â  Â  Â  Â  for line in res:
Â  Â  Â  Â  Â  Â  Â  Â  st.write(line)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.balloons()
Â  Â  Â  Â  Â  Â  st.success("Ø£Ø­Ø³Ù†Øª! Ø§Ù„Ù†Ø·Ù‚ Ø³Ù„ÙŠÙ….")

else:
Â  Â  st.error("ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù arabic_phonetics.csv")








